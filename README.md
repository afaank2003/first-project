# final-project
INST126 final project
# Roman Empire Inscriptions Analysis

## Overview
This project analyzes an archaeological dataset to determine which provinces of the Roman Empire have the most known inscriptions.

## Requirements
- Python 3.x
- Pandas library

## Dataset
This dataset was created by merging two datasets provided by Epigraphic Database Heidelberg (EDH), a large project aimed at collecting Roman inscriptions from around the world. The project is run by Heidelberg University, Germany, with support from many other institutions around the world. This dataset contains detailed information on many inscriptions, including province, city, coordinates, year of find, and notable words in the inscription.

## Usage
To run the program, simply run the Python code, and make sure space is available for the CSV that will be downloaded. 

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Rain Forecaster

## Description
The Rain Forecaster is a Python script designed to predict rain based on geographical coordinates (latitude and longitude). It utilizes the National Weather Service's API to fetch real-time weather data, specifically focusing on identifying the occurrence of rain. 
## Usage Instructions
1. **Entering Coordinates**: When prompted, enter the latitude and longitude in the format `xx.xxxx,-yy.yyyy`. Ensure the coordinates are accurate to get the correct weather forecast.
2. **Running the Script**: Execute the script in a Python environment. It automatically connects to the National Weather Service's API and fetches the hourly weather forecast for the provided coordinates.
3. **Interpreting Results**: The script processes the fetched data and identifies if there's a rain forecast in the upcoming hours. It stops and displays the forecast as soon as it encounters a prediction of rain.
4. **Dependencies**: Ensure that the `requests` library is installed in your Python environment, as the script uses this to make HTTP requests.

## Credits
- **National Weather Service (NWS)**: This script relies on the NWS API for weather data. The NWS provides reliable and up-to-date weather information.

## Disclaimer
- The accuracy of the rain forecast is subject to the data provided by the National Weather Service.

## Contact
For any queries or issues related to the script, users can reach out to the script's maintenance team or the National Weather Service for API-related inquiries.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

These two files should satisfy the requirements that I had leftover:

6.1 You wrote documentation in the form of a README. 6.2 You wrote documentation in comments at the top of a script. 6.5 You wrote documentation sufficient to enable someone else to use your script/program. 6.7 You chose an appropriate license for your program/script. 6.8 You made appropriate use of another person’s license when incorporating their software

5.1 You used a while-loop to iterate continuously until a condition is reached. 5.2 You used a counter inside a loop to trigger a special condition after a certain number of loops or events. 5.3 You gave users a way to exit out of a while loop (by breaking the loop or exiting the program). 5.5 You used a for-loop to iterate over a list. 5.6 You used a loop to print or save output iteratively. 5.9 You appended an item to a list iteratively (i.e., inside a loop). 5.11 You removed an item from a list iteratively (i.e., inside a loop

10.1 You found a simple web page and described what data you wanted to scrape from it. 10.2 You used bs4 to scrape a simple web page. 10.3 You used ’polite’ code to scrape a web page and described your approach. 10.4 You used an API to obtain JSON or other formatted data. 10.5 You extracted or manipulated values from JSON formatted data. Progress Chart • NOTE: you only have to complete EITHER items 10.1 through 10.3 OR items 10.4 and 10.5 • In other words, you can get credit for this Advanced Topic by either scraping a page or using data from an API

9.1 You created a git repo. 9.2 You added and committed at least 3 separate commits, with meaningful commit messages. 9.3 You published a repo on a remote site like GitHub. 9.4 You cloned a git repo and committed your own changes. 9.5 You submitted a complete git repo or link to a git repo to submit your work. Progress Chart • NOTE: you only need to complete ONE of either 9.3 or 9.4 • In other words, if you don’t want to publish on GitHub (9.3), you just need to demonstrate that you know how to pull from GitHub and commit new changes (9.4). • TIP: if you create a repo for your final project (9.1), commit several changes with good commit messages (9.2), publish it on GitHub (9.3), and send the link for your final submission (9.5), you will have completed this Topic.

8_1 You used an narray or Series to perform a vectorized computation instead of a loop or comprehension. 8_2 You read in a CSV of data into a data frame object using pandas. 8_3 You used pandas to get a subset of a data frame using a boolean. 8_4 You wrote data that you created or changed to a CSV using pandas
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
